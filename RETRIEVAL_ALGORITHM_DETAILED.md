# ğŸ§  THUáº¬T TOÃN CHI TIáº¾T - Lá»šP RETRIEVER

## ğŸ¯ **Tá»”NG QUAN**

Lá»›p `Retriever` thá»±c hiá»‡n **multi-hop reasoning** vá»›i **paragraph-level processing** Ä‘á»ƒ tÃ¬m supporting facts cho cÃ¢u há»i Ä‘a hop. Thuáº­t toÃ¡n sá»­ dá»¥ng **beam search** Ä‘á»ƒ track multiple hypotheses vÃ  **progressive concatenation** Ä‘á»ƒ build multi-hop reasoning.

---

## ğŸ”„ **FLOW CHÃNH - FORWARD METHOD**

### **INPUT:**
- `q_codes`: List chá»©a clean question tokens `[question_tokens]`  
- `p_codes`: List paragraph sequences `[CLS] + Q + P + [SEP]` (Ä‘Ã£ Ä‘Æ°á»£c pre-tokenized)
- `sf_idx`: Supporting fact indices (context-level)
- `hop`: Sá»‘ hops cho inference mode
- `context_mapping`: Mapping tá»« paragraph index â†’ original context index

### **OUTPUT:**
- `current_preds`: Context-level predictions (main output)
- `final_preds`: Alias cho backward compatibility  
- `paragraph_preds`: Paragraph-level predictions (detailed)
- `loss`: Training loss

---

## ğŸ“‹ **BÆ¯á»šC 1: INITIALIZATION**

```python
# 1.1 Thiáº¿t láº­p device vÃ  cÃ¡c hÃ m loss
device = q_codes[0].device
total_loss = torch.tensor(0.0, device=device, requires_grad=True)
loss_function = nn.CrossEntropyLoss()
focal_loss_function = FocalLoss() if self.use_focal else None

# 1.2 TrÃ­ch xuáº¥t Ä‘áº§u vÃ o (ğŸš€ ÄÃƒ Tá»I Æ¯U - khÃ´ng cáº§n trÃ­ch xuáº¥t context!)
question_tokens = q_codes[0]  # Token cÃ¢u há»i Ä‘Ã£ lÃ m sáº¡ch
all_paragraph_sequences = p_codes  # CÃ¡c Ä‘oáº¡n vÄƒn Ä‘Ã£ Ä‘Æ°á»£c tokenize trÆ°á»›c!
context_to_paragraph_mapping = context_mapping or list(range(len(p_codes)))

# 1.3 XÃ¡c Ä‘á»‹nh sá»‘ hop
if self.training:
    sf_idx = sf_idx[0]
    hops = len(sf_idx)  # Sá»‘ lÆ°á»£ng supporting facts
else:
    hops = hop if hop > 0 else 2  # Máº·c Ä‘á»‹nh 2 hop cho inference
```

**Äiá»ƒm chÃ­nh:**
- ğŸš€ **Tá»I Æ¯U HÃ“A**: KhÃ´ng cÃ²n trÃ­ch xuáº¥t context! Sá»­ dá»¥ng cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Ã£ tÃ¡ch sáºµn trá»±c tiáº¿p
- **Hop Ä‘á»™ng**: Cháº¿ Ä‘á»™ training dá»±a trÃªn sá»‘ supporting facts, cháº¿ Ä‘á»™ inference dÃ¹ng tham sá»‘

---

## ğŸ¥‡ **BÆ¯á»šC 2: HOP 1 - INDEPENDENT PARAGRAPH SCORING**

### **2.1 Chuáº©n bá»‹ Tensor**
```python
max_len = max(len(seq) for seq in all_paragraph_sequences)
num_paragraphs = len(all_paragraph_sequences)

# Táº¡o tensor theo batch cho táº¥t cáº£ Ä‘oáº¡n vÄƒn
hop1_qp_ids = torch.zeros([num_paragraphs, max_len], device=device, dtype=torch.long)
hop1_qp_attention_mask = torch.zeros([num_paragraphs, max_len], device=device, dtype=torch.long)

# Äiá»n tensor vá»›i cÃ¡c chuá»—i Ä‘oáº¡n vÄƒn
for i, paragraph_seq in enumerate(all_paragraph_sequences):
    seq_len = len(paragraph_seq)
    hop1_qp_ids[i, :seq_len] = paragraph_seq
    hop1_qp_attention_mask[i, :seq_len] = (paragraph_seq != pad_token_id).long()
```

### **2.2 Táº¡o nhÃ£n (Chá»‰ khi Training)**
```python
if self.training:
    hop1_label = torch.zeros([num_paragraphs], dtype=torch.long, device=device)
    
    for i, paragraph_seq in enumerate(all_paragraph_sequences):
        original_ctx_idx = context_to_paragraph_mapping[i]
        if original_ctx_idx in sf_idx:  # Context há»— trá»£
            hop1_label[i] = 1  # NhÃ£n tÃ­ch cá»±c
```

### **2.3 Forward Pass**
```python
# Encoder forward: [num_paragraphs, seq_len] â†’ [num_paragraphs, hidden_size]
hop1_encoder_outputs = self.encoder(hop1_qp_ids, hop1_qp_attention_mask)[0][:, 0, :]

# PhÃ¢n loáº¡i: [num_paragraphs, hidden_size] â†’ [num_paragraphs, 2]
hop1_projection = self.hop_classifier_layer(hop1_encoder_outputs)

# TÃ­nh toÃ¡n loss
if self.training:
    total_loss += CrossEntropyLoss(hop1_projection, hop1_label)
```

### **2.4 Chá»n Beam**
```python
# Chá»n top beam_size Ä‘oáº¡n vÄƒn dá»±a trÃªn Ä‘iá»ƒm sá»‘ lá»›p tÃ­ch cá»±c
_, hop1_pred_paragraphs = hop1_projection[:, 1].topk(self.beam_size, dim=-1)

# Khá»Ÿi táº¡o theo dÃµi beam
current_preds = [[idx.item()] for idx in hop1_pred_paragraphs]  # Má»—i beam = [para_idx]

# TrÃ­ch xuáº¥t token Ä‘oáº¡n vÄƒn Ä‘Ã£ chá»n cho multi-hop
selected_paragraph_tokens = []
for pred_idx in hop1_pred_paragraphs:
    selected_seq = all_paragraph_sequences[pred_idx.item()]
    paragraph_tokens = _extract_paragraph_tokens(selected_seq, question_tokens)
    selected_paragraph_tokens.append([paragraph_tokens])  # Má»—i beam = [para_tokens]
```

**Thuáº­t toÃ¡n chÃ­nh:**
- **Cháº¥m Ä‘iá»ƒm Ä‘á»™c láº­p**: Má»—i Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c cháº¥m Ä‘iá»ƒm Ä‘á»™c láº­p vá»›i cÃ¢u há»i
- **Chá»n TopK**: Chá»n `beam_size=2` Ä‘oáº¡n vÄƒn cÃ³ Ä‘iá»ƒm cao nháº¥t
- **TrÃ­ch xuáº¥t token**: TrÃ­ch xuáº¥t token Ä‘oáº¡n vÄƒn Ä‘á»ƒ chuáº©n bá»‹ cho multi-hop

---

## ğŸ”— **BÆ¯á»šC 3: HOP 2+ - MULTI-HOP COMBINATION**

### **3.1 Má»Ÿ rá»™ng Beam**
```python
for hop_idx in range(1, hops):  # Bá» qua hop 0 (Ä‘Ã£ hoÃ n thÃ nh)
    next_sequences = []      # Chuá»—i á»©ng viÃªn cho hop nÃ y
    next_labels = []         # NhÃ£n training
    next_pred_mapping = []   # Ãnh xáº¡ ngÆ°á»£c vá» chá»‰ sá»‘ Ä‘oáº¡n vÄƒn
    
    # Vá»›i má»—i beam tá»« hop trÆ°á»›c
    for beam_idx in range(self.beam_size):
        beam_selected_paragraphs = selected_paragraph_tokens[beam_idx]  # Lá»±a chá»n trÆ°á»›c Ä‘Ã³
        beam_used_indices = set(current_preds[beam_idx])                # Chá»‰ sá»‘ Ä‘oáº¡n vÄƒn Ä‘Ã£ dÃ¹ng
        
        # Thá»­ má»—i Ä‘oáº¡n vÄƒn chÆ°a sá»­ dá»¥ng lÃ m á»©ng viÃªn tiáº¿p theo
        for para_idx, paragraph_seq in enumerate(all_paragraph_sequences):
            if para_idx in beam_used_indices:
                continue  # Bá» qua cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Ã£ chá»n
```

### **3.2 Táº¡o chuá»—i Multi-hop**
```python
# TrÃ­ch xuáº¥t token Ä‘oáº¡n vÄƒn má»›i
new_paragraph_tokens = _extract_paragraph_tokens(paragraph_seq, question_tokens)

# Táº¡o káº¿t ná»‘i tiáº¿n bá»™: [CLS] + Q + P1 + P2 + ... + Pnew + [SEP]
multi_hop_seq = _create_multi_hop_sequence(
    question_tokens,           # Token cÃ¢u há»i sáº¡ch
    beam_selected_paragraphs,  # Lá»±a chá»n hop trÆ°á»›c  
    new_paragraph_tokens       # Äoáº¡n vÄƒn á»©ng viÃªn má»›i
)

next_sequences.append(multi_hop_seq)
next_pred_mapping.append(current_preds[beam_idx] + [para_idx])  # Theo dÃµi lá»±a chá»n
```

**Äá»‹nh dáº¡ng chuá»—i Multi-hop:**
```
Hop 1: [CLS] + Q + P1 + [SEP]
Hop 2: [CLS] + Q + P1 + P2 + [SEP]  
Hop 3: [CLS] + Q + P1 + P2 + P3 + [SEP]
```

### **3.3 Táº¡o nhÃ£n (Training)**
```python
if self.training:
    new_pred_set = set(current_preds[beam_idx] + [para_idx])
    target_contexts = set()
    
    # Ãnh xáº¡ chá»‰ sá»‘ Ä‘oáº¡n vÄƒn vá» chá»‰ sá»‘ context
    for p_idx in new_pred_set:
        target_contexts.add(context_to_paragraph_mapping[p_idx])
    
    # Kiá»ƒm tra xem tá»• há»£p cÃ³ khá»›p vá»›i supporting facts má»¥c tiÃªu
    if target_contexts == set(sf_idx[:hop_idx+1]):
        next_labels.append(1)  # Tá»• há»£p Ä‘Ãºng
    else:
        next_labels.append(0)  # Tá»• há»£p sai
```

### **3.4 Forward Pass**
```python
# Chuáº©n bá»‹ tensor
max_len = max(len(seq) for seq in next_sequences)
num_candidates = len(next_sequences)

hop_qp_ids = torch.zeros([num_candidates, max_len], device=device, dtype=torch.long)
hop_qp_attention_mask = torch.zeros([num_candidates, max_len], device=device, dtype=torch.long)

# Äiá»n tensor
for i, seq in enumerate(next_sequences):
    seq_len = len(seq)
    hop_qp_ids[i, :seq_len] = seq
    hop_qp_attention_mask[i, :seq_len] = (seq != pad_token_id).long()

# Forward pass
hop_encoder_outputs = self.encoder(hop_qp_ids, hop_qp_attention_mask)[0][:, 0, :]
hop_projection = self.hop_n_classifier_layer(hop_encoder_outputs)

# TÃ­nh toÃ¡n loss
if self.training:
    if self.use_focal:
        total_loss += FocalLoss(hop_projection, hop_label)
    else:
        total_loss += CrossEntropyLoss(hop_projection, hop_label)
```

### **3.5 Cáº­p nháº­t Beam**
```python
# Chá»n top beam_size á»©ng viÃªn
_, hop_pred_indices = hop_projection[:, 1].topk(self.beam_size, dim=-1)

# Cáº­p nháº­t theo dÃµi beam
new_current_preds = []
new_selected_paragraph_tokens = []

for pred_idx in hop_pred_indices:
    selected_prediction = next_pred_mapping[pred_idx.item()]
    new_current_preds.append(selected_prediction)
    
    # XÃ¢y dá»±ng láº¡i danh sÃ¡ch token Ä‘oáº¡n vÄƒn cho beam nÃ y
    beam_paragraph_tokens = []
    for para_idx in selected_prediction:
        para_seq = all_paragraph_sequences[para_idx]
        para_tokens = _extract_paragraph_tokens(para_seq, question_tokens)
        beam_paragraph_tokens.append(para_tokens)
    
    new_selected_paragraph_tokens.append(beam_paragraph_tokens)

# Cáº­p nháº­t cho vÃ²ng láº·p tiáº¿p theo
current_preds = new_current_preds
selected_paragraph_tokens = new_selected_paragraph_tokens
```

**Thuáº­t toÃ¡n chÃ­nh:**
- **Má»Ÿ rá»™ng tá»• há»£p**: Má»—i beam thá»­ vá»›i má»i Ä‘oáº¡n vÄƒn chÆ°a sá»­ dá»¥ng
- **Káº¿t ná»‘i tiáº¿n bá»™**: XÃ¢y dá»±ng chuá»—i multi-hop tá»«ng bÆ°á»›c
- **Beam pruning**: Chá»‰ giá»¯ top `beam_size` á»©ng viÃªn má»—i hop

---

## ğŸ“¤ **BÆ¯á»šC 4: SINH Äáº¦U RA**

### **4.1 Chuyá»ƒn Ä‘á»•i Paragraph â†’ Dá»± Ä‘oÃ¡n Context**
```python
final_context_preds = []
for beam_paragraphs in current_preds:
    context_indices = []
    for para_idx in beam_paragraphs:
        ctx_idx = context_to_paragraph_mapping[para_idx]
        if ctx_idx not in context_indices:  # TrÃ¡nh trÃ¹ng láº·p
            context_indices.append(ctx_idx)
    final_context_preds.append(context_indices)
```

### **4.2 Tráº£ vá» Káº¿t quáº£**
```python
return {
    'current_preds': final_context_preds,    # Äáº§u ra chÃ­nh (cáº¥p context)
    'final_preds': final_context_preds,      # TÆ°Æ¡ng thÃ­ch ngÆ°á»£c
    'paragraph_preds': current_preds,        # Chi tiáº¿t (cáº¥p Ä‘oáº¡n vÄƒn)
    'loss': total_loss                       # Loss training
}
```

---

## ğŸ”§ **CÃC PHÆ¯Æ NG THá»¨C Há»– TRá»¢**

### **_extract_paragraph_tokens()**
```python
def _extract_paragraph_tokens(sequence, question_tokens):
    """TrÃ­ch xuáº¥t token Ä‘oáº¡n vÄƒn tá»« chuá»—i [CLS] + Q + P + [SEP]"""
    # Äá»‹nh dáº¡ng chuá»—i: [CLS] + Q + P + [SEP]
    question_start = 1  # Bá» qua [CLS]
    question_end = question_start + len(question_tokens)
    paragraph_start = question_end
    paragraph_end = len(sequence) - 1  # Bá» qua [SEP] cuá»‘i
    
    if paragraph_start < paragraph_end:
        return sequence[paragraph_start:paragraph_end]
    else:
        return torch.tensor([])  # Rá»—ng náº¿u khÃ´ng cÃ³ ná»™i dung Ä‘oáº¡n vÄƒn
```

### **_create_multi_hop_sequence()**
```python
def _create_multi_hop_sequence(question_tokens, selected_paragraphs, new_paragraph):
    """Táº¡o chuá»—i multi-hop tiáº¿n bá»™"""
    # XÃ¢y dá»±ng chuá»—i: [CLS] + Q + P1 + P2 + ... + Pnew + [SEP]
    sequence_parts = [
        torch.tensor([cls_token_id]),
        question_tokens
    ]
    
    # ThÃªm cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Ã£ chá»n tá»« hop trÆ°á»›c
    for paragraph_tokens in selected_paragraphs:
        if len(paragraph_tokens) > 0:
            sequence_parts.append(paragraph_tokens)
    
    # ThÃªm Ä‘oáº¡n vÄƒn má»›i
    if len(new_paragraph) > 0:
        sequence_parts.append(new_paragraph)
    
    # ThÃªm [SEP] cuá»‘i
    sequence_parts.append(torch.tensor([sep_token_id]))
    
    # Káº¿t há»£p vÃ  xá»­ lÃ½ cáº¯t ngáº¯n
    combined_sequence = torch.cat(sequence_parts)
    if len(combined_sequence) > max_seq_len:
        # Cáº¯t ngáº¯n thÃ´ng minh: giá»¯ [CLS] + Q + [SEP], cáº¯t ngáº¯n Ä‘oáº¡n vÄƒn
        combined_sequence = combined_sequence[:max_seq_len-1]
        combined_sequence = torch.cat([combined_sequence, torch.tensor([sep_token_id])])
    
    return combined_sequence
```

---

## ğŸ¯ **Äáº¶C ÄIá»‚M THUáº¬T TOÃN**

### **1. LÃ½ luáº­n Multi-hop Tiáº¿n bá»™**
- **Hop 1**: Cháº¥m Ä‘iá»ƒm Ä‘oáº¡n vÄƒn Ä‘á»™c láº­p `[CLS] + Q + P + [SEP]`
- **Hop 2**: Cháº¥m Ä‘iá»ƒm tá»• há»£p `[CLS] + Q + P1 + P2 + [SEP]`  
- **Hop 3**: LÃ½ luáº­n má»Ÿ rá»™ng `[CLS] + Q + P1 + P2 + P3 + [SEP]`

### **2. Theo dÃµi Beam Search**
- **Nhiá»u giáº£ thuyáº¿t**: Duy trÃ¬ `beam_size=2` á»©ng viÃªn
- **NgÄƒn trÃ¹ng láº·p**: KhÃ´ng chá»n láº¡i Ä‘oáº¡n vÄƒn Ä‘Ã£ sá»­ dá»¥ng
- **Chá»n tá»‘i Æ°u**: Chá»n TopK táº¡i má»—i hop

### **3. Äáº§u ra Hai cáº¥p**
- **Cáº¥p Context**: `current_preds` cho cÃ¡c tÃ¡c vá»¥ downstream
- **Cáº¥p Äoáº¡n vÄƒn**: `paragraph_preds` cho phÃ¢n tÃ­ch chi tiáº¿t

### **4. Chiáº¿n lÆ°á»£c Training**
- **Hop 1**: CrossEntropy loss cho cháº¥m Ä‘iá»ƒm Ä‘á»™c láº­p
- **Hop 2+**: Focal Loss cho class imbalance (tÃ¹y chá»n)
- **NhÃ£n tiáº¿n bá»™**: Khá»›p chÃ­nh xÃ¡c vá»›i supporting facts má»¥c tiÃªu

### **5. Tá»‘i Æ°u hÃ³a Bá»™ nhá»›**
- **PhÃ©p toÃ¡n vÃ©c tÆ¡ hÃ³a**: Xá»­ lÃ½ batch cho hiá»‡u quáº£
- **Cáº¯t ngáº¯n thÃ´ng minh**: Æ¯u tiÃªn cÃ¢u há»i vÃ  token Ä‘áº·c biá»‡t
- **Quáº£n lÃ½ thiáº¿t bá»‹**: Sá»­ dá»¥ng thiáº¿t bá»‹ nháº¥t quÃ¡n

---

## ğŸ“Š **PHÃ‚N TÃCH Äá»˜ PHá»¨C Táº P**

### **Äá»™ phá»©c táº¡p Thá»i gian**
- **Hop 1**: O(P Ã— L) vá»›i P=Ä‘oáº¡n vÄƒn, L=Ä‘á»™ dÃ i chuá»—i
- **Hop 2+**: O(B Ã— P Ã— L) vá»›i B=beam_size  
- **Tá»•ng cá»™ng**: O(H Ã— B Ã— P Ã— L) vá»›i H=sá»‘ hop

### **Äá»™ phá»©c táº¡p KhÃ´ng gian**
- **LÆ°u trá»¯ Ä‘oáº¡n vÄƒn**: O(P Ã— L)
- **Theo dÃµi beam**: O(H Ã— B Ã— P)
- **Tráº¡ng thÃ¡i encoder**: O(P Ã— D) vá»›i D=hidden_size

---

## ğŸ” **VÃ Dá»¤ THá»°C HIá»†N**

### **Äáº§u vÃ o:**
- CÃ¢u há»i: "Thá»§ Ä‘Ã´ cá»§a PhÃ¡p lÃ  gÃ¬?"
- Äoáº¡n vÄƒn: [P1: "ThÃ´ng tin PhÃ¡p...", P2: "ThÃ´ng tin Paris...", P3: "ThÃ´ng tin Äá»©c..."]
- Má»¥c tiÃªu: [0, 1] (context 0 vÃ  1 lÃ  há»— trá»£)

### **Hop 1:**
- Cháº¥m Ä‘iá»ƒm táº¥t cáº£: P1=0.8, P2=0.9, P3=0.3
- Chá»n top-2: [P2, P1] 
- Beam: [[P2], [P1]]

### **Hop 2:**
- Beam 1: Thá»­ P2+P1, P2+P3 â†’ Äiá»ƒm: 0.95, 0.4
- Beam 2: Thá»­ P1+P2, P1+P3 â†’ Äiá»ƒm: 0.95, 0.2  
- Chá»n top-2: [P2+P1, P1+P2] (cÃ¹ng tá»• há»£p)
- Cuá»‘i: [[P1, P2], [P1, P2]]

### **Äáº§u ra:**
- Dá»± Ä‘oÃ¡n context: [[1, 0], [1, 0]]
- Dá»± Ä‘oÃ¡n Ä‘oáº¡n vÄƒn: [[2, 1], [1, 2]]

Thuáº­t toÃ¡n nÃ y Ä‘áº£m báº£o lÃ½ luáº­n multi-hop chÃ­nh xÃ¡c vá»›i kháº£ nÄƒng xá»­ lÃ½ cÃ¡c context phá»©c táº¡p! ğŸš€
