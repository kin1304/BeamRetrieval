# üöÄ H∆∞·ªõng d·∫´n ch·∫°y tr√™n GPU

## üçé Apple Silicon (MPS)

N·∫øu b·∫°n c√≥ Mac v·ªõi chip Apple Silicon (M1/M2/M3):

```bash
# Training t·ªëi ∆∞u cho Apple Silicon
python run_mps_training.py

# Ho·∫∑c manual v·ªõi batch size l·ªõn h∆°n
python train.py --batch_size=6 --samples=1000 --epochs=3
```

## üî• NVIDIA GPU (CUDA)

N·∫øu b·∫°n c√≥ GPU NVIDIA v·ªõi CUDA:

```bash
# Training v·ªõi GPU v√† mixed precision
python train.py --gpu --mixed_precision --batch_size=8 --samples=5000 --epochs=3

# GPU l·ªõn (>8GB VRAM)
python train.py --gpu --mixed_precision --batch_size=16 --gradient_accumulation=2

# GPU nh·ªè (<4GB VRAM) 
python train.py --gpu --mixed_precision --batch_size=4 --gradient_accumulation=8
```

## ‚öôÔ∏è T·ªëi ∆∞u h√≥a Memory

### Gi·∫£m memory s·ª≠ d·ª•ng:
```bash
# Gi·∫£m max_len
python train.py --max_len=64 --batch_size=8

# Gradient accumulation thay v√¨ batch size l·ªõn
python train.py --batch_size=2 --gradient_accumulation=8

# Gi·∫£m s·ªë contexts
python train.py --batch_size=4  # Default 5 contexts
```

### TƒÉng hi·ªáu su·∫•t:
```bash
# Mixed precision (ch·ªâ CUDA)
python train.py --mixed_precision --batch_size=8

# Gradient checkpointing (ti·∫øt ki·ªám memory)
python train.py --batch_size=4  # T·ª± ƒë·ªông b·∫≠t trong model
```

## üß† Mixed Precision l√† g√¨?

**Mixed Precision** l√† k·ªπ thu·∫≠t s·ª≠ d·ª•ng c·∫£ **FP16** (16-bit) v√† **FP32** (32-bit) floating point trong c√πng m·ªôt model:

### üìä So s√°nh ƒë·ªô ch√≠nh x√°c:
- **FP32** (Single): 32-bit, ƒë·ªô ch√≠nh x√°c cao, memory nhi·ªÅu
- **FP16** (Half): 16-bit, ƒë·ªô ch√≠nh x√°c th·∫•p h∆°n, memory √≠t h∆°n 50%
- **Mixed**: D√πng FP16 cho forward pass, FP32 cho gradients

### ‚úÖ ∆Øu ƒëi·ªÉm:
- **TƒÉng t·ªëc ƒë·ªô**: 1.5-2x nhanh h∆°n tr√™n GPU Tensor Core
- **Ti·∫øt ki·ªám memory**: Gi·∫£m 50% VRAM usage
- **Batch size l·ªõn h∆°n**: C√≥ th·ªÉ train v·ªõi batch size g·∫•p ƒë√¥i
- **ƒê·ªô ch√≠nh x√°c**: V·∫´n gi·ªØ ƒë∆∞·ª£c quality nh∆∞ FP32

### ‚öôÔ∏è C√°ch ho·∫°t ƒë·ªông:
```python
# Forward pass: FP16 (nhanh, √≠t memory)
with torch.cuda.amp.autocast():
    outputs = model(inputs)
    loss = criterion(outputs, targets)

# Backward pass: FP32 (ch√≠nh x√°c)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### üéØ Khi n√†o s·ª≠ d·ª•ng:
- ‚úÖ **NVIDIA GPU** v·ªõi Tensor Cores (RTX 20xx, 30xx, 40xx, V100, A100)
- ‚úÖ **Large models** (>100M parameters)
- ‚úÖ **Memory limited** (GPU <8GB)
- ‚ùå **Apple Silicon** (ch∆∞a h·ªó tr·ª£)
- ‚ùå **CPU training**

### üìà Performance boost:
```bash
# Kh√¥ng mixed precision
python train.py --batch_size=4    # ~6GB VRAM, 45s/epoch

# V·ªõi mixed precision  
python train.py --mixed_precision --batch_size=8  # ~6GB VRAM, 25s/epoch
```

## üìä Monitoring GPU

```bash
# Theo d√µi GPU usage (NVIDIA)
nvidia-smi -l 1

# Theo d√µi Apple Silicon
sudo powermetrics -n 1 --samplers gpu_power
```

## üîß Troubleshooting

### CUDA Out of Memory:
```bash
# Gi·∫£m batch size
python train.py --batch_size=2 --gradient_accumulation=8

# Gi·∫£m sequence length
python train.py --max_len=64

# D·ªçn cache
python -c "import torch; torch.cuda.empty_cache()"
```

### MPS Issues:
```bash
# Fallback to CPU n·∫øu MPS c√≥ v·∫•n ƒë·ªÅ
export PYTORCH_ENABLE_MPS_FALLBACK=1
python train.py --batch_size=4
```

## üèÜ Recommended Settings

### Apple Silicon M1/M2/M3:
```bash
python train.py --batch_size=6 --samples=2000 --epochs=3 --max_len=128
```

### RTX 3090/4090 (24GB):
```bash
python train.py --gpu --mixed_precision --batch_size=16 --samples=10000 --epochs=5
```

### RTX 3080/4080 (12GB):
```bash
python train.py --gpu --mixed_precision --batch_size=8 --samples=5000 --epochs=3
```

### RTX 3070/4070 (8GB):
```bash
python train.py --gpu --mixed_precision --batch_size=6 --gradient_accumulation=2
```

### GTX 1660/RTX 3060 (6GB):
```bash
python train.py --gpu --mixed_precision --batch_size=4 --gradient_accumulation=4
```

## üéØ Format Input m·ªõi

Model hi·ªán s·ª≠ d·ª•ng format: `[CLS] + Question + Context + [SEP]`

- Kh√¥ng c√≤n [SEP] gi·ªØa Question v√† Context
- ƒê∆°n gi·∫£n v√† hi·ªáu qu·∫£ h∆°n
- T∆∞∆°ng th√≠ch v·ªõi BERT standard practices

## ‚úÖ Verification

Sau khi training, ki·ªÉm tra:

```bash
# Test model
python test_format.py

# Ki·ªÉm tra saved model
ls -la models/retriever_trained.pt
```
